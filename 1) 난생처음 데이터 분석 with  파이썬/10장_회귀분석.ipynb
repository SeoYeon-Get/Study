{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **10장. 회귀분석**"
      ],
      "metadata": {
        "id": "sNDYx985Y1qF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hKqY9BZwYnI1"
      },
      "outputs": [],
      "source": [
        "#회귀분석 : 어떤 사건에 대한 여러 요인의 영향력을 파악하고 비교할 수 있음.\n",
        "#상관분석으로 두 변수의 선형 상관도를 판단할 수 있으나 이것이 인과관계를 나타내지는 않음\n",
        "#선형 회귀분석(Linear regression analysis) : 데이터를 하나의 직선으로 이어 일차함수로 일반화하는 데이터 분석 방법\n",
        "#로지스틱 회귀분석 : 결과 사건의 발생 확률로 원인 사건의 영향력을 수치화하는 데이터 분석 방법"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#선형 회귀분석\n",
        "# - x 변수(독립변수, Independent variable)가 원인, y 변수(종속변수, Dependent Variable가 결과\n",
        "# - 독립변수는 한 개 이상, 종속변수는 단 한개만 존재\n",
        "# - 독립변수가 한 개이면 단순 선형 회귀분석, 독립변수가 두 개이상이면 다중 선형 회귀분석\n",
        "# - 잔차(Residual) : 점이 가리키는 값과 직선이 예측하는 값의 차\n",
        "# - 결정계수(R square) : 모형이 데이터의 패턴을 얼마나 효과적으로 보여주는지 수치화한 값\n",
        "#                        0 이상 1이하의 값으로 계산됨. 1에 가까워질수록 잔차가 작고 예측의 정말도가 높음.\n",
        "# - 편차(Deviation) : 평균과 실제 값의 차이\n",
        "# - 수정된 결정계수(adjusted R square) : 독립변수의 개수가 많을수록 커지는 결정계수의 문제점을 보완하기 위해 수정된 결정계수. 다중 선형 회귀분석에서 사용\n",
        "\n",
        "# 선형 회귀분석의 해석\n",
        "# - 통계적 가설검정(Statistical hypothesis test) : 통계적 추측 방법, 모집단에 대한 추측(가설)을 하고 표본의 정보를 기준으로 그 가설이 타당한지 판정하는 방법\n",
        "# - 귀무가설(Null hypothesis) : 처음부터 거짓일 것으로 기대하는 가설\n",
        "# - 대립가설(Alternative hypothesis) : 입증하고자 하는 가설\n",
        "# - 유의수준(Significance level), p-값(p-value, 유의확률)"
      ],
      "metadata": {
        "id": "VhIkvdVTiiF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 연봉과 직장 만족도\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x = [3000, 4200, 4000, 5000, 6000, 3800, 3500, 6200, 3900, 4500]\n",
        "y = [60, 75, 70, 85, 90, 70, 65, 95, 70, 80]\n",
        "data = {'x' : x, 'y': y}\n",
        "df = pd.DataFrame(data)\n",
        "plt.scatter(df['x'], df['y'])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "Pu-ViY0diiIJ",
        "outputId": "f20ca2f8-e86f-428d-ec41-05d53fd9f508"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#단순 선형 회귀분석\n",
        "\n",
        "from statsmodels.formula.api import ols\n",
        "from sklearn.linear_model import LinearRegression #sklearn.linear_model: 선형 회귀분석 라이브러리\n",
        "\n",
        "fit = ols('y~x', data=df).fit() # ols() : 선형 회귀분석을 수행하는 함수\n",
        "print(fit.summary())\n",
        "\n",
        "#결정계수 R의 값이 0.971로, 표본 데이터들에 대한 설명력이 97.1%이다.\n",
        "#회귀모형의 독립변수는 x 한개이며, x의 유의수준은 0.000으로 0.05미만 -> x는 유의한 독립변수이다.\n",
        "#독립변수 x의 계수는 0.0107\n",
        "#회귀모형 : y = 0.0107x + 29.0004 + e"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54lsczhNiiKa",
        "outputId": "e00e3f54-3e0f-4498-8334-9c4aba2d1fd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                      y   R-squared:                       0.971\n",
            "Model:                            OLS   Adj. R-squared:                  0.968\n",
            "Method:                 Least Squares   F-statistic:                     271.0\n",
            "Date:                Mon, 27 Nov 2023   Prob (F-statistic):           1.87e-07\n",
            "Time:                        07:49:08   Log-Likelihood:                -20.111\n",
            "No. Observations:                  10   AIC:                             44.22\n",
            "Df Residuals:                       8   BIC:                             44.83\n",
            "Df Model:                           1                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "Intercept     29.0004      2.926      9.913      0.000      22.254      35.747\n",
            "x              0.0107      0.001     16.463      0.000       0.009       0.012\n",
            "==============================================================================\n",
            "Omnibus:                        0.346   Durbin-Watson:                   2.871\n",
            "Prob(Omnibus):                  0.841   Jarque-Bera (JB):                0.447\n",
            "Skew:                           0.286   Prob(JB):                        0.800\n",
            "Kurtosis:                       2.136   Cond. No.                     2.07e+04\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The condition number is large, 2.07e+04. This might indicate that there are\n",
            "strong multicollinearity or other numerical problems.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scipy/stats/_stats_py.py:1806: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=10\n",
            "  warnings.warn(\"kurtosistest only valid for n>=20 ... continuing \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#다중 선형 회귀분석\n",
        "\n",
        "from statsmodels.formula.api import ols\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "salary = [3000, 4200, 4000, 5000, 6000, 3800, 3500, 6200, 3900, 4500]\n",
        "breakTime = [120, 60, 100, 100, 50, 120, 90, 40, 120, 120]\n",
        "workingTime = [8, 6, 10, 8, 10, 10, 9, 7, 8, 9]\n",
        "companySatisfaction = [60, 75, 70, 85, 90, 70, 65, 95, 70, 80]\n",
        "\n",
        "data = {'salary': salary, 'breakTime': breakTime, 'workingTime': workingTime,\n",
        "        'companySatisfaction': companySatisfaction}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "fit = ols('companySatisfaction ~ salary + breakTime + workingTime', data=df).fit()\n",
        "print(fit.summary())\n",
        "\n",
        "# 수정된 결정계수 : 0.988, 이 선형 회귀모형의 설명력이 98.8%\n",
        "# 변수 salary는 p-값이 0.000, 변수 breakTime은 0.047로 0.05보다 작음, workingTime p-값은 0.057로 0.05보다 큼\n",
        "# -> 연봉과 휴식시간은 유의한 독립변수이며, 근무시간은 유의하지 않은 독립변수이다.\n",
        "# 모형 : companySatisfaction = 24.9819 + (0.0120)*salary + (0.0668)*breakTime + e"
      ],
      "metadata": {
        "id": "m2pFEBSPiiM1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "811360a3-a662-4b16-cfc6-520ffd49182c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                             OLS Regression Results                            \n",
            "===============================================================================\n",
            "Dep. Variable:     companySatisfaction   R-squared:                       0.988\n",
            "Model:                             OLS   Adj. R-squared:                  0.982\n",
            "Method:                  Least Squares   F-statistic:                     164.0\n",
            "Date:                 Mon, 27 Nov 2023   Prob (F-statistic):           3.81e-06\n",
            "Time:                         08:19:58   Log-Likelihood:                -15.777\n",
            "No. Observations:                   10   AIC:                             39.55\n",
            "Df Residuals:                        6   BIC:                             40.77\n",
            "Df Model:                            3                                         \n",
            "Covariance Type:             nonrobust                                         \n",
            "===============================================================================\n",
            "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
            "-------------------------------------------------------------------------------\n",
            "Intercept      24.9819      5.353      4.667      0.003      11.884      38.080\n",
            "salary          0.0120      0.001     15.895      0.000       0.010       0.014\n",
            "breakTime       0.0668      0.027      2.491      0.047       0.001       0.132\n",
            "workingTime    -0.9718      0.412     -2.356      0.057      -1.981       0.037\n",
            "==============================================================================\n",
            "Omnibus:                        0.929   Durbin-Watson:                   2.500\n",
            "Prob(Omnibus):                  0.628   Jarque-Bera (JB):                0.752\n",
            "Skew:                          -0.441   Prob(JB):                        0.686\n",
            "Kurtosis:                       1.986   Cond. No.                     5.06e+04\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The condition number is large, 5.06e+04. This might indicate that there are\n",
            "strong multicollinearity or other numerical problems.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scipy/stats/_stats_py.py:1806: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=10\n",
            "  warnings.warn(\"kurtosistest only valid for n>=20 ... continuing \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#로지스틱 회귀모형\n",
        "# - 선형 회귀분석의 종속변수는 어떤 값이든 될 수 있지만 로지스틱 회귀분석의 종속변수는 범위에 제한이 있음\n",
        "# - 범위 : 0 에서 1, 종속변수가 1에 가까울수록 사건이 발생할 확률이 더 높음\n",
        "# - 오즈비(Odds Ratio, OR) : 승산비, 사건이 발생할 확률이 발생하지 않을 확률에 비해 몇 배나 높은지를 의미"
      ],
      "metadata": {
        "id": "djIXSCB6iiPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "sales = [1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0]\n",
        "price = [1500, 2000, 5000, 3000, 3500, 2500, 4000, 4500, 3000, 4500, 4000, 4500, 5500, 6500, 5000, 3500, 7000]\n",
        "data = {'sales' : sales, 'price' : price}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "logis = sm.Logit.from_formula('sales~price', data = df).fit() # sm.Logit.from_formula() : 로지스틱 회귀분석 수행 함수\n",
        "print(logis.summary())\n",
        "print('OR')\n",
        "print(np.exp(logis.params))\n",
        "\n",
        "# price의 p-값이 0.04로 유의한 변수, y졀편인 Intercept p-값 0.046도 확인할 수 있음.\n",
        "# 변수 price의 오즈비가 0.998433이므로 가격을 올렸을 때 판매될 가능성이 판매되지 않을 가능성의 0.998433배이다."
      ],
      "metadata": {
        "id": "7n778Cb5iiRP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed1714c4-c5e8-4168-8c68-95bdc9ff403b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimization terminated successfully.\n",
            "         Current function value: 0.430873\n",
            "         Iterations 7\n",
            "                           Logit Regression Results                           \n",
            "==============================================================================\n",
            "Dep. Variable:                  sales   No. Observations:                   17\n",
            "Model:                          Logit   Df Residuals:                       15\n",
            "Method:                           MLE   Df Model:                            1\n",
            "Date:                Mon, 27 Nov 2023   Pseudo R-squ.:                  0.3768\n",
            "Time:                        08:35:40   Log-Likelihood:                -7.3248\n",
            "converged:                       True   LL-Null:                       -11.754\n",
            "Covariance Type:            nonrobust   LLR p-value:                  0.002917\n",
            "==============================================================================\n",
            "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "Intercept      6.5752      3.300      1.993      0.046       0.108      13.042\n",
            "price         -0.0016      0.001     -2.008      0.045      -0.003   -3.75e-05\n",
            "==============================================================================\n",
            "OR\n",
            "Intercept    717.058841\n",
            "price          0.998433\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#타이타닉 탑승자 생존여부 예측\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "titanic = sns.load_dataset('titanic')\n",
        "print(titanic)"
      ],
      "metadata": {
        "id": "LcS37hXQiiTg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f406c99-61b3-424a-8eff-c06485f778fc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     survived  pclass     sex   age  sibsp  parch     fare embarked   class  \\\n",
            "0           0       3    male  22.0      1      0   7.2500        S   Third   \n",
            "1           1       1  female  38.0      1      0  71.2833        C   First   \n",
            "2           1       3  female  26.0      0      0   7.9250        S   Third   \n",
            "3           1       1  female  35.0      1      0  53.1000        S   First   \n",
            "4           0       3    male  35.0      0      0   8.0500        S   Third   \n",
            "..        ...     ...     ...   ...    ...    ...      ...      ...     ...   \n",
            "886         0       2    male  27.0      0      0  13.0000        S  Second   \n",
            "887         1       1  female  19.0      0      0  30.0000        S   First   \n",
            "888         0       3  female   NaN      1      2  23.4500        S   Third   \n",
            "889         1       1    male  26.0      0      0  30.0000        C   First   \n",
            "890         0       3    male  32.0      0      0   7.7500        Q   Third   \n",
            "\n",
            "       who  adult_male deck  embark_town alive  alone  \n",
            "0      man        True  NaN  Southampton    no  False  \n",
            "1    woman       False    C    Cherbourg   yes  False  \n",
            "2    woman       False  NaN  Southampton   yes   True  \n",
            "3    woman       False    C  Southampton   yes  False  \n",
            "4      man        True  NaN  Southampton    no   True  \n",
            "..     ...         ...  ...          ...   ...    ...  \n",
            "886    man        True  NaN  Southampton    no   True  \n",
            "887  woman       False    B  Southampton   yes   True  \n",
            "888  woman       False  NaN  Southampton    no  False  \n",
            "889    man        True    C    Cherbourg   yes   True  \n",
            "890    man        True  NaN   Queenstown    no   True  \n",
            "\n",
            "[891 rows x 15 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#타이타닉 탑승자 데이터의 로지스틱 회귀분석\n",
        "\n",
        "import statsmodels.api as sm\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(titanic['sex'])\n",
        "sex = encoder.transform(titanic['sex']) #encoder.transform() : 성별 열의 값 'male'과 'female'을 각각 1과 0으로 변환\n",
        "titanic['sex'] = sex\n",
        "\n",
        "model = sm.Logit.from_formula('survived ~ pclass + sex + age + fare + parch + sibsp' , data = titanic)\n",
        "logit = model.fit()\n",
        "print(logit.summary())\n",
        "\n",
        "print(\"OR\")\n",
        "print(np.exp(logit.params))\n",
        "\n",
        "#독립변수 중 p-값이 0.05미만인 변수 : pclass, sex, age, sibsp\n",
        "#-> 위의 변수의 계수가 모두 음수이므로 독립변수의 값이 증가할 때마다 생존가능성이 낮은 것으로 판단\n",
        "#탑승 클래스의 숫자가 높을수록 생존율이 낮고, 남성(1)이 여성(0)에 비해 생존율이 낮고, 나이가 많을수록 생존율이 낮으며, 자녀나 배우자의 수가 많을수록 생존율이 낮음.\n",
        "#독립변수 중 생존에 가장 큰 영향을 미치는 변수는 절댓값이 가장 큰 변수 sex이다.\n",
        "#유의한 독립변수 중 age의 오즈비가 가장 크고, sex의 오즈비가 가장 작다.\n",
        "#-> 나이가 많은 사람이 생존할 확률은 나이가 적은 사람이 생존할 확률과 비슷, 남성이 생존할 확률은 여성의 생존할 확률의 0.07배로 매우 작음."
      ],
      "metadata": {
        "id": "jMbN2gEjiiVs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e68b939b-daae-4310-b86b-38847760a36a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimization terminated successfully.\n",
            "         Current function value: 0.445244\n",
            "         Iterations 6\n",
            "                           Logit Regression Results                           \n",
            "==============================================================================\n",
            "Dep. Variable:               survived   No. Observations:                  714\n",
            "Model:                          Logit   Df Residuals:                      707\n",
            "Method:                           MLE   Df Model:                            6\n",
            "Date:                Tue, 28 Nov 2023   Pseudo R-squ.:                  0.3408\n",
            "Time:                        04:53:30   Log-Likelihood:                -317.90\n",
            "converged:                       True   LL-Null:                       -482.26\n",
            "Covariance Type:            nonrobust   LLR p-value:                 5.727e-68\n",
            "==============================================================================\n",
            "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "Intercept      5.3890      0.604      8.926      0.000       4.206       6.572\n",
            "pclass        -1.2422      0.163     -7.612      0.000      -1.562      -0.922\n",
            "sex           -2.6348      0.220    -11.998      0.000      -3.065      -2.204\n",
            "age           -0.0440      0.008     -5.374      0.000      -0.060      -0.028\n",
            "fare           0.0022      0.002      0.866      0.386      -0.003       0.007\n",
            "parch         -0.0619      0.123     -0.504      0.614      -0.303       0.179\n",
            "sibsp         -0.3758      0.127     -2.950      0.003      -0.625      -0.126\n",
            "==============================================================================\n",
            "OR\n",
            "Intercept    218.984972\n",
            "pclass         0.288734\n",
            "sex            0.071730\n",
            "age            0.956999\n",
            "fare           1.002162\n",
            "parch          0.939942\n",
            "sibsp          0.686771\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#아파트  매매가격의 요인 분석\n",
        "\n",
        "#독립변수 : 면적(size), 아파트가 얼마나 오래되었는지(age), 편의시설(kindergarten(어린이집), elementarySchool(초등학교까지의 거리), busStop(버스정류장까지의 거리),\n",
        "#           hospital(병/의원까지의 거리), mart(마트까지의 거리))\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pylab as plt\n",
        "from statsmodels.formula.api import ols\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "price = [174000, 156500, 168000, 145000, 172500, 178000, 168500, 176000, 205000,\n",
        "         166800, 169000, 152300, 169500, 164000, 153500, 153500, 147500, 123500,\n",
        "         115000, 132000, 132000, 127500, 136800, 135000, 140000, 137700, 130000,\n",
        "         136500, 99900, 105000, 126000, 126000, 103000, 106000, 148000, 131000,\n",
        "         133000, 108500, 97000, 167000, 95000, 95000, 143000, 107000, 119000,\n",
        "         96000, 129700, 104700, 152000, 100000, 102500, 106000, 113000, 109000,\n",
        "         109800, 141000, 136000, 133000, 115000, 155000, 134000, 130000, 140000,\n",
        "         117500, 138800, 149000, 100000, 139500, 160500, 150000]\n",
        "size  = [152, 118, 118, 85, 118, 152, 118, 152, 162, 118, 118, 85, 118, 118, 85,\n",
        "         85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 60, 60, 85, 85, 60,\n",
        "         60, 169, 85, 85, 60, 60, 169, 60, 60, 112, 112, 85, 60, 85, 60, 112,\n",
        "         85, 60, 60, 60, 60, 60, 138, 85, 85, 60, 138, 85, 85, 85, 60, 85, 128,\n",
        "         59, 128, 128, 115]\n",
        "age = [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19,\n",
        "       19,19, 19, 19, 18, 18, 18, 18, 18, 18, 23, 23, 23, 23, 23, 23, 23, 23,\n",
        "       23, 23, 23, 23, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22,\n",
        "       22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 11, 11, 11, 11, 11]\n",
        "kindergarten = [22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22,\n",
        "                22, 6, 6, 6, 6, 6, 14, 14, 14, 14, 14, 14, 9, 9, 9, 9, 9, 9, 9,\n",
        "                9, 9, 9, 9, 9, 6, 6, 6, 6, 6, 6, 6, 6, 6, 10, 10, 10, 10, 10,\n",
        "                10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 4, 4, 4, 4, 4]\n",
        "elementarySchool = [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
        "                    10, 10, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 2, 2, 2, 2, 2, 2,\n",
        "                    2, 2, 2, 2, 2, 2, 10, 10, 10, 10, 10, 10, 10, 10, 10, 7, 7,\n",
        "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 12, 12, 12, 12, 12]\n",
        "busStop = [13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
        "           32, 32, 32, 32, 32, 16, 16, 16, 16, 16, 16, 12, 12, 12, 12, 12, 12,\n",
        "           12, 12, 12, 12, 12, 12, 15, 15, 15, 15, 15, 15, 15, 15, 15, 13, 13, 13,\n",
        "           13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 29, 29, 29, 29, 29]\n",
        "hospital = [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19,\n",
        "            20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 12, 12, 12, 12, 12,\n",
        "            12, 12, 12, 12, 12, 12, 16, 16, 16, 16, 16, 16, 16, 16, 16, 19, 19, 19,\n",
        "            19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 14, 14, 14, 14, 14]\n",
        "mart = [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 17,\n",
        "        17, 17, 17, 17, 21, 21, 21, 21, 21, 21, 23, 23, 23, 23, 23, 23, 23, 23,\n",
        "        23, 23, 23, 23, 15, 15, 15, 15, 15, 15, 15, 15, 15, 19, 19, 19, 19, 19,\n",
        "        19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 14, 14, 14, 14, 14]\n",
        "\n",
        "data = {'price' : price, 'size' : size, 'age' : age, 'kindergarten' : kindergarten, 'elementarySchool' : elementarySchool, \\\n",
        "        'busStop': busStop, 'hospital':hospital, 'mart':mart}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "fit = ols('price ~ size + age + kindergarten + elementarySchool + busStop + hospital + mart', data=df).fit()\n",
        "print(fit.summary())\n",
        "\n",
        "#수정된 결정계수 = 0.862, 이 모형은 86.2%의 설명력을 갖춤\n",
        "#유의한 변수는 size, kindergarten\n",
        "#변수 size의 계수는 534.9026, kindergarten의 계수는 1927.0880\n",
        "#모형 : price = 0.0000169 + (534.9026)*size + (1927.0880)*kindergarten + e\n",
        "#아파트 매매가격에 영향을 미치는 요인 : 면적과 유치원까지의 거리\n",
        "#면적이 1 제곱미터 커질 때 매매가격이 약 535만원 비싸지며, 유치원까지 도보 소요시간이 1분 증가할 때 매매가격이 약 1,927만원 비싸짐\n",
        "#그러나, 특정 지점까지 도보 소요시간이 길어질수록 매매가격이 비싸진다는 해석은 일반적이지 않음.\n",
        "#데이터의 시간적, 공간적 범위르 넓히고 독립변수도 추가하여 다시 분석해 볼 필요가 있음."
      ],
      "metadata": {
        "id": "z15k7MBdiiYC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63c10058-5dcd-4a5b-d17e-7744d5dbc719"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                  price   R-squared:                       0.876\n",
            "Model:                            OLS   Adj. R-squared:                  0.862\n",
            "Method:                 Least Squares   F-statistic:                     62.45\n",
            "Date:                Tue, 28 Nov 2023   Prob (F-statistic):           1.11e-25\n",
            "Time:                        05:23:49   Log-Likelihood:                -734.71\n",
            "No. Observations:                  70   AIC:                             1485.\n",
            "Df Residuals:                      62   BIC:                             1503.\n",
            "Df Model:                           7                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "====================================================================================\n",
            "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------------\n",
            "Intercept         1.169e+05   1.23e+05      0.948      0.347    -1.3e+05    3.64e+05\n",
            "size               534.9026     43.081     12.416      0.000     448.785     621.021\n",
            "age              -1460.9677   1754.535     -0.833      0.408   -4968.233    2046.298\n",
            "kindergarten      1927.0880    591.638      3.257      0.002     744.421    3109.755\n",
            "elementarySchool -1599.1185   3858.456     -0.414      0.680   -9312.062    6113.825\n",
            "busStop            -13.2131    730.790     -0.018      0.986   -1474.042    1447.616\n",
            "hospital           737.2488    891.948      0.827      0.412   -1045.730    2520.227\n",
            "mart             -1372.4907   3583.901     -0.383      0.703   -8536.606    5791.625\n",
            "==============================================================================\n",
            "Omnibus:                        4.208   Durbin-Watson:                   2.150\n",
            "Prob(Omnibus):                  0.122   Jarque-Bera (JB):                3.332\n",
            "Skew:                          -0.446   Prob(JB):                        0.189\n",
            "Kurtosis:                       3.589   Cond. No.                     1.17e+04\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The condition number is large, 1.17e+04. This might indicate that there are\n",
            "strong multicollinearity or other numerical problems.\n"
          ]
        }
      ]
    }
  ]
}